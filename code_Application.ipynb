{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Wwhc8yrqBv"
      },
      "source": [
        "# Installation des d√©pendances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y0mL4OTrs5W"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install diffusers[torch] transformers accelerate xformers fastai gradio peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww-3S5jtrxN3"
      },
      "source": [
        "### üìö Importations\n",
        "- `torch` : pour le traitement avec PyTorch et le contr√¥le du g√©n√©rateur al√©atoire.\n",
        "- `StableDiffusionXLPipeline` & `DPMSolverMultistepScheduler` : composants essentiels de `diffusers` pour g√©n√©rer des images avec SDXL.\n",
        "- `UNet2DConditionModel` & `PeftModel` : pour charger et appliquer le mod√®le UNet fine-tun√© avec LoRA.\n",
        "- `gradio` : biblioth√®que pour cr√©er facilement une interface web interactive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ELQwu8Yr0-T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler\n",
        "from peft import PeftModel\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs2phjKSr6dl"
      },
      "source": [
        "### ‚úèÔ∏è Fonction `optimize_prompt`\n",
        "Cette fonction g√©n√®re :\n",
        "- un **prompt positif** optimis√© selon le produit, la couleur et la description, adapt√© au format du fine-tuning ;\n",
        "- un **prompt n√©gatif** pour exclure les d√©fauts courants (basse qualit√©, d√©formations...).\n",
        "\n",
        "Elle permet d'am√©liorer la qualit√© du rendu g√©n√©r√© par le mod√®le Stable Diffusion XL fine-tun√©."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USR6kq9Tr9B2"
      },
      "outputs": [],
      "source": [
        "def optimize_prompt(product_type, color, description):\n",
        "    phrasing = {\n",
        "        \"T-shirt\": {\n",
        "            \"modif\": \"illustration d√©taill√©e sur t-shirt\",\n",
        "            \"style\": \"style r√©aliste, haute r√©solution, √©clairage dramatique, rendu artistique, impression de qualit√©\"\n",
        "        },\n",
        "        \"Mug\": {\n",
        "            \"modif\": \"illustration d√©taill√©e sur mug\",\n",
        "            \"style\": \"style r√©aliste, haute r√©solution, √©clairage doux, rendu artistique, impression de qualit√©\"\n",
        "        },\n",
        "        \"Casquette\": {\n",
        "            \"modif\": \"illustration brod√©e sur casquette\",\n",
        "            \"style\": \"style simple, contraste √©lev√©, impression nette, rendu textile\"\n",
        "        },\n",
        "        \"Coussin\": {\n",
        "            \"modif\": \"motif harmonieux sur coussin\",\n",
        "            \"style\": \"style d√©coratif, haute r√©solution, textile de qualit√©\"\n",
        "        },\n",
        "        \"Tableau\": {\n",
        "            \"modif\": \"impression fine art sur toile\",\n",
        "            \"style\": \"style artistique, composition √©quilibr√©e, d√©tails fins, galerie d'art, rendu haut de gamme\"\n",
        "        }\n",
        "    }\n",
        "    this = phrasing.get(product_type, phrasing[\"T-shirt\"])\n",
        "    support = f\"{this['modif']} {color}\"\n",
        "    optimized_prompt = f\"{description}, {support}, {this['style']}\"\n",
        "    negative_prompt = \"d√©form√©, basse qualit√©, pixelis√©, flou, proportions incorrectes, anatomie incorrecte, texte illisible, signature, logo, watermark\"\n",
        "    return optimized_prompt, negative_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG9nFmvLr_LD"
      },
      "source": [
        "### ‚öôÔ∏è Chargement du mod√®le\n",
        "- On utilise **Stable Diffusion XL base 1.0** avec pr√©cision `float16` pour acc√©l√©rer l‚Äôinf√©rence.\n",
        "- Le UNet est charg√© et adapt√© avec **LoRA** via `PeftModel` pour int√©grer le fine-tuning local.\n",
        "- Le scheduler est remplac√© par **DPMSolverMultistep** pour des r√©sultats plus rapides et pr√©cis.\n",
        "- Le pipeline est transf√©r√© sur GPU (`cuda`) pour de meilleures performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO9hyoKWsBay"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "LORA_PATH = \"fine_tuned_sdxl_ecommerce/unet_lora\"  # Chemin vers tes poids LoRA sauvegard√©s\n",
        "\n",
        "# Charger le UNet de base\n",
        "unet = UNet2DConditionModel.from_pretrained(\n",
        "    MODEL_ID, subfolder=\"unet\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True\n",
        ")\n",
        "\n",
        "# Appliquer le LoRA local\n",
        "unet = PeftModel.from_pretrained(unet, LORA_PATH)\n",
        "\n",
        "# Fusionner pour l'inf√©rence\n",
        "unet = unet.merge_and_unload()\n",
        "\n",
        "# Charger le pipeline sans UNet, puis assigner\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    unet=unet,  # Assign the modified UNet\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Scheduler pour des r√©sultats rapides/pr√©cis\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "print(\"Mod√®le SDXL fine-tun√© charg√© et pr√™t !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFPFNIPmsEgJ"
      },
      "source": [
        "### üñºÔ∏è Fonction `generate_image`\n",
        "Elle permet de :\n",
        "- Construire un **prompt optimis√©** et un **prompt n√©gatif**.\n",
        "- G√©n√©rer une image de **768x768 px** avec un nombre d‚Äô√©tapes et un `guidance scale` personnalisable.\n",
        "- Utiliser un `seed` pour reproductibilit√© si fourni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ht5XdkYsGtt"
      },
      "outputs": [],
      "source": [
        "def generate_image(product_type, color, description, steps, guidance, seed):\n",
        "    prompt, negative_prompt = optimize_prompt(product_type, color, description)\n",
        "    try:\n",
        "        if seed is not None and int(seed) != -1:\n",
        "            generator = torch.Generator(\"cuda\").manual_seed(int(seed))\n",
        "        else:\n",
        "            generator = None\n",
        "    except Exception:\n",
        "        generator = None\n",
        "    result = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=int(steps),\n",
        "        guidance_scale=float(guidance),\n",
        "        width=768,\n",
        "        height=768,\n",
        "        generator=generator\n",
        "    )\n",
        "    image = result.images[0]\n",
        "    return image, prompt, negative_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJcWtuWisIz7"
      },
      "source": [
        "### üß∞ Interface Gradio\n",
        "- Interface responsive avec **Gradio Blocks**.\n",
        "- Entr√©es : produit, couleur, description + options avanc√©es (`steps`, `guidance`, `seed`).\n",
        "- Sorties : image g√©n√©r√©e, prompt optimis√©, prompt n√©gatif.\n",
        "- `on_generate` : ex√©cute la g√©n√©ration avec les valeurs d'entr√©e.\n",
        "- `clear_fields` : r√©initialise tous les champs aux valeurs par d√©faut.\n",
        "- `generate_btn.click(...)` : connecte le bouton √† la fonction de g√©n√©ration.\n",
        "- `clear_btn.click(...)` : connecte le bouton √† la fonction de r√©initialisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vofxXHLNsL7H"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "        # üé® <span style='color:#8f6ed5'>G√©n√©rateur d'Images de Produits Personnalis√©s</span>\n",
        "        <span style=\"font-size:1.1em;\">\n",
        "        Saisissez le type de produit, une couleur et votre id√©e <br>\n",
        "        Obtenez un rendu <b>photor√©aliste</b>&nbsp;: id√©al pour vos boutiques en ligne‚ÄØ!\n",
        "        </span>\n",
        "    \"\"\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            product_type = gr.Dropdown([\"T-shirt\", \"Mug\", \"Casquette\", \"Coussin\", \"Tableau\"], label=\"Type de produit\", value=\"T-shirt\")\n",
        "            color = gr.Dropdown([\"blanc\", \"noir\", \"bleu\", \"rouge\", \"vert\"], label=\"Couleur\", value=\"blanc\")\n",
        "            description = gr.Textbox(label=\"Description\", placeholder=\"Votre description ici\")\n",
        "            with gr.Accordion(\"Param√®tres avanc√©s\", open=False):\n",
        "                steps = gr.Slider(20, 50, value=30, step=1, label=\"√âtapes de diffusion\")\n",
        "                guidance = gr.Slider(5.0, 9.0, value=7.5, step=0.1, label=\"Guidance Scale\")\n",
        "                seed = gr.Number(value=-1, label=\"Seed (-1 pour al√©atoire)\")\n",
        "            generate_btn = gr.Button(\"‚ú® G√©n√©rer\")\n",
        "            clear_btn = gr.Button(\"üßπ Effacer\")\n",
        "        with gr.Column():\n",
        "            output_image = gr.Image(label=\"Aper√ßu produit\", type=\"pil\")\n",
        "            optimized_prompt = gr.Textbox(label=\"Prompt optimis√© r√©el\")\n",
        "            negative_prompt = gr.Textbox(label=\"Prompt n√©gatif\")\n",
        "\n",
        "    # Mover les appels .click() √† l'int√©rieur du bloc `with gr.Blocks() as demo:`\n",
        "    def on_generate(*vals):\n",
        "        return generate_image(*vals)\n",
        "\n",
        "    def clear_fields():\n",
        "        # Restaure les valeurs par d√©faut\n",
        "        return (\"T-shirt\", \"blanc\", \"\", 30, 7.5, -1, None, \"\", \"\")\n",
        "\n",
        "    generate_btn.click(\n",
        "        on_generate,\n",
        "        inputs=[product_type, color, description, steps, guidance, seed],\n",
        "        outputs=[output_image, optimized_prompt, negative_prompt]\n",
        "    )\n",
        "    clear_btn.click(\n",
        "        clear_fields,\n",
        "        None,\n",
        "        [product_type, color, description, steps, guidance, seed, output_image, optimized_prompt, negative_prompt]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-w7RS7ssRuv"
      },
      "source": [
        "### üöÄ Lancement de l'application Gradio\n",
        "- L‚Äôinterface est lanc√©e avec `share=True` pour obtenir un **lien public** accessible depuis n‚Äôimporte quel navigateur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st7mYLtgsTeM"
      },
      "outputs": [],
      "source": [
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
